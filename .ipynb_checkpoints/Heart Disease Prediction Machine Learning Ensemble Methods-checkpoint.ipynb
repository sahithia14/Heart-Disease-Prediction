{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data analysis\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# for data visuals\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "# for machine learning \n",
    "from sklearn.ensemble import RandomForestClassifier as RFclassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier as ADclassifier\n",
    "from sklearn.ensemble import BaggingClassifier as BGclassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier as ETclassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBclassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Reading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainData = pd.read_csv('processed_cleveland_data_train.csv')\n",
    "testData = pd.read_csv('processed_cleveland_data_test.csv')\n",
    "\n",
    "# replacing anything greater than 1 with 1 because it is a binary classification problem\n",
    "def replace_predict(df):\n",
    "    df['num'] = df['num'].replace([1, 2, 3, 4, 5, 6], 1)\n",
    "\n",
    "\n",
    "       \n",
    "replace_predict(trainData)\n",
    "replace_predict(testData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the train and test data sets are further seprated by thier features and the predicted diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xtrain = trainData.drop(['num'], axis=1)\n",
    "Ytrain = trainData['num']\n",
    "\n",
    "Xtest = testData.drop(['num'], axis=1)\n",
    "Ytest = testData['num']\n",
    "\n",
    "Ytrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define the model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "# Create all the model\n",
    "\n",
    "rfModel=RFclassifier()\n",
    "adModel= ADclassifier()\n",
    "bgModel=BGclassifier()\n",
    "etModel=ETclassifier()\n",
    "gbModel=GBclassifier()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the best algorithm to the data, and decides choosen parameters \n",
    "rfModel.fit(Xtrain, Ytrain)\n",
    "adModel.fit(Xtrain, Ytrain)\n",
    "bgModel.fit(Xtrain, Ytrain)\n",
    "etModel.fit(Xtrain, Ytrain)\n",
    "gbModel.fit(Xtrain, Ytrain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5a: Evaluate the Model using accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalaccu=[]\n",
    "models=[rfModel,adModel,bgModel,etModel,gbModel]\n",
    "count=0\n",
    "while count<5:\n",
    "    predictions = models[count].predict(Xtest)\n",
    "    print(models[count])\n",
    "    print(predictions)\n",
    "    accuracy= accuracy_score(Ytest, predictions)\n",
    "    count=count+1\n",
    "    finalaccu.append(accuracy)\n",
    "print(finalaccu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss(true_label, predicted_prob):\n",
    "   if true_label == 1:\n",
    "     return -log(predicted_prob)\n",
    "   else:\n",
    "    return -log(1 - predicted_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5b: Evaluate Model using confidence and probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "finalconf=[]\n",
    "models=[rfModel,adModel,bgModel,etModel,gbModel]\n",
    "count=0\n",
    "while count<5:\n",
    "    confidence = models[count].predict_proba(Xtest)\n",
    "    probs = confidence[:, 1]\n",
    "    loss = log_loss(Ytest.values, probs)\n",
    "    print(loss)\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cross Validation with KFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "alldata = pd.read_csv('processed_cleveland_data.csv')\n",
    "replace_predict(alldata)\n",
    "\n",
    "Xall = alldata.drop(['num'], axis=1)\n",
    "Yall = alldata['num']\n",
    "\n",
    "def run_kfold(model):\n",
    "    kf = KFold(n_splits=5)\n",
    "    outcomes = []\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(Xall):\n",
    "        fold += 1\n",
    "        Xtrain, Xtest = Xall.values[train_index], Xall.values[test_index]\n",
    "        Ytrain, Ytest = Yall.values[train_index], Yall.values[test_index]\n",
    "        model.fit(Xtrain, Ytrain)\n",
    "        print(Ytrain[0])\n",
    "        predictions = model.predict(Xtest)\n",
    "        print(predictions)\n",
    "        accuracy = accuracy_score(Ytest, predictions)\n",
    "        print(accuracy)\n",
    "        outcomes.append(accuracy)\n",
    "        print(outcomes)\n",
    "        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy)) \n",
    "        mean_outcome = np.mean(outcomes)\n",
    "        print(\"Mean Accuracy: {0}\".format(mean_outcome)) \n",
    "        \n",
    "run_kfold(model)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
