{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data analysis\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# for data visuals\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "# for machine learning \n",
    "from sklearn.ensemble import RandomForestClassifier as RFclassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNclassifier \n",
    "from sklearn.svm import SVC as SVMclassifier\n",
    "from sklearn.naive_bayes import GaussianNB as NBclassifier\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Reading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainData = pd.read_csv('processed_cleveland_data_train.csv')\n",
    "testData = pd.read_csv('processed_cleveland_data_test.csv')\n",
    "\n",
    "# replacing anything greater than 1 with 1 because it is a binary classification problem\n",
    "def replace_predict(df):\n",
    "    df['num'] = df['num'].replace([1, 2, 3, 4, 5, 6], 1)\n",
    "\n",
    "\n",
    "    \n",
    "replace_predict(trainData)\n",
    "replace_predict(testData)\n",
    "\n",
    "\n",
    "# rescaling dara\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "Xtrain = trainData.drop(['num'], axis=1)\n",
    "Ytrain = trainData['num']\n",
    "\n",
    "\n",
    "Xtest = testData.drop(['num'], axis=1)\n",
    "Ytest = testData['num']\n",
    "\n",
    "Xtrain = scaler.fit_transform(Xtrain)\n",
    "Xtest = scaler.fit_transform(Xtest)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define the model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "# Create all the models\n",
    "\n",
    "rfModel=RFclassifier()\n",
    "knModel= KNclassifier()\n",
    "svmModel= SVMclassifier()\n",
    "nbModel=NBclassifier() \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the best algorithm to the data\n",
    "rfModel.fit(Xtrain, Ytrain)\n",
    "knModel.fit(Xtrain, Ytrain)\n",
    "svmModel.fit(Xtrain, Ytrain)\n",
    "nbModel.fit(Xtrain, Ytrain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4a: Evaluate model using accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "finalaccu=[]\n",
    "predictionsAr=[]\n",
    "probabilities=[]\n",
    "models=[rfModel,knModel,svmModel,nbModel]\n",
    "count=0\n",
    "while count<4:\n",
    "    predictions = models[count].predict(Xtest)\n",
    "    print(models[count])\n",
    "    print(predictions)\n",
    "    accuracy= accuracy_score(Ytest, predictions)\n",
    "    count=count+1\n",
    "    finalaccu.append(accuracy)\n",
    "    predictionsAr.append(predictions)\n",
    "print(finalaccu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods =  [\"Random Forest\",\"KNN\", \"SVM\", \"Naive Bayes\"]\n",
    "accuracy = [80.33, 67.21, 49.18, 77.04]\n",
    "colors = [\"purple\", \"green\", \"orange\", \"#CFC60E\"]\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.yticks(np.arange(0,100,10))\n",
    "plt.ylabel(\"Accuracy Percent\")\n",
    "plt.xlabel(\"Algorithms\")\n",
    "sns.barplot(x=methods, y=accuracy, palette=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4b : Evaluate model using confusion matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm_knn = confusion_matrix(Ytest,predictionsAr[1])\n",
    "cm_svm = confusion_matrix(Ytest,predictionsAr[2])\n",
    "cm_nb = confusion_matrix(Ytest,predictionsAr[3])\n",
    "cm_rf = confusion_matrix(Ytest,predictionsAr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,12))\n",
    "\n",
    "plt.suptitle(\"Confusion Matrixes\",fontsize=24)\n",
    "plt.subplots_adjust(wspace = 0.4, hspace= 0.4)\n",
    "\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "plt.title(\"K Nearest Neighbors Confusion Matrix\")\n",
    "sns.heatmap(cm_knn,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False)\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "plt.title(\"Support Vector Machine Confusion Matrix\")\n",
    "sns.heatmap(cm_svm,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False)\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "plt.title(\"Naive Bayes Confusion Matrix\")\n",
    "sns.heatmap(cm_nb,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False)\n",
    "\n",
    "plt.subplot(2,3,6)\n",
    "plt.title(\"Random Forest Confusion Matrix\")\n",
    "sns.heatmap(cm_rf,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4c: Evaluate model using ROC/AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "#RANDOM FOREST\n",
    "probs = rfModel.predict_proba(Xtest)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(Ytest, probs)\n",
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr)\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "#calulate ROC AUC score\n",
    "loss = roc_auc_score(Ytest, probs)\n",
    "print(loss)\n",
    "\n",
    "\n",
    "#KNN\n",
    "probs = knModel.predict_proba(Xtest)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(Ytest, probs)\n",
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr)\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "#calulate ROC AUC score\n",
    "loss = roc_auc_score(Ytest, probs)\n",
    "print(loss)\n",
    "\n",
    "\n",
    "#NAIVE BAYES\n",
    "probs = nbModel.predict_proba(Xtest)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(Ytest, probs)\n",
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr)\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "#calulate ROC AUC score\n",
    "loss = roc_auc_score(Ytest, probs)\n",
    "print(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4d: Evaluate model using confidence and probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "finalconf=[]\n",
    "models=[rfModel,adModel,bgModel,etModel,gbModel]\n",
    "count=0\n",
    "while count<5:\n",
    "    confidence = models[count].predict_proba(Xtest)\n",
    "    probs = confidence[:, 1]\n",
    "    loss = log_loss(Ytest.values, probs)\n",
    "    print(loss)\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4e: Evaluate model using Mathew's Correlation Coeffcient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "count=0\n",
    "while count<4:\n",
    " matthewsCoeff=matthews_corrcoef(Ytest, predictionsAr[count])   \n",
    " count=count+1\n",
    " print(matthewsCoeff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Feature Importance Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \n",
    "          \"thal\"]\n",
    "\n",
    "importances = rfModel.feature_importances_\n",
    "print(importances)\n",
    "indices = np.argsort(importances)\n",
    "print(indices)\n",
    "plt.figure(1)\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods =  [\"Random Forest\",\"KNN\", \"SVM\", \"Naive Bayes\"]\n",
    "MCC = [0.57, 0.35, 0.0, 0.56]\n",
    "colors = [\"purple\", \"green\", \"blue\", \"#CFC60E\"]\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.yticks(np.arange(-1,1,0.1))\n",
    "plt.ylabel(\"Matthews Correlation Coefficient\")\n",
    "plt.xlabel(\"Algorithms\")\n",
    "sns.barplot(x=methods, y=MCC, palette=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cross Validation with KFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "alldata = pd.read_csv('processed_cleveland_data.csv')\n",
    "replace_predict(alldata)\n",
    "\n",
    "Xall = alldata.drop(['num'], axis=1)\n",
    "Yall = alldata['num']\n",
    "\n",
    "def run_kfold(model):\n",
    "    kf = KFold(n_splits=5)\n",
    "    outcomes = []\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(Xall):\n",
    "        fold += 1\n",
    "        Xtrain, Xtest = Xall.values[train_index], Xall.values[test_index]\n",
    "        Ytrain, Ytest = Yall.values[train_index], Yall.values[test_index]\n",
    "        model.fit(Xtrain, Ytrain)\n",
    "        print(Ytrain[0])\n",
    "        predictions = model.predict(Xtest)\n",
    "        print(predictions)\n",
    "        accuracy = accuracy_score(Ytest, predictions)\n",
    "        print(accuracy)\n",
    "        outcomes.append(accuracy)\n",
    "        print(outcomes)\n",
    "        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy)) \n",
    "        mean_outcome = np.mean(outcomes)\n",
    "        print(\"Mean Accuracy: {0}\".format(mean_outcome)) \n",
    "        \n",
    "run_kfold(model)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
